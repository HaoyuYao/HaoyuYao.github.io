<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Haoyu Yao</title><meta name="author" content="Haoyu Yao (姚皓宇)"><link rel="shortcut icon" href="/img/icon.jpg"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https：//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Haoyu Yao</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/about"> 🔍 Detailed Information (CN)</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http：//schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null；this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>Haoyu Yao (姚皓宇)</h3><p class="author-bio">Computer Vision <br>Multimodal Learning <br> Generative Model <br> <br> 武汉大学 <br>  遥感信息工程学院 <br> 空间信息与数字技术</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https：//github.com/HaoyuYao" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-stack-overflow" aria-hidden="true"></i></a></li><li><a class="social-icon" href="tencent：//AddContact/?fromId=50&amp；fromSubId=1&amp；subcmd=all&amp；uin=1597083201" target="_blank"><i class="fab fa-qq" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto：[2022302111077@whu.edu.cn]" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul></div></div></div><div class="page" itemscope itemtype="http：//schema.org/CreativeWork"><h5 class="page-title">About Me</h5><article><hr>
<h2> 🚀 基本信息 </h2>
<p>📊 <strong>成绩排名</strong>：</p>
<ul>
    <li>GPA: <strong>3.93 / 4.0</strong>, 加权均分: <strong>93.36 / 100</strong></li>
    <li>成绩排名: <strong>2 / 41</strong> 或 <strong>4 / 350</strong></li>
    <li>综合排名: <strong>1 / 41</strong> 或 <strong>1 / 350</strong></li>
</ul>
<p>📚 <strong>专业能力</strong>：</p>
<ul>
    <li>高等数学A1/A2（99、97）、线性代数（99）、概率论与数理统计（97）</li>
    <li>数据结构与算法 （100）、面向对象的程序设计 （99）、计算机网络与应用 （98）、数据库原理及应用 （95）</li>
    <li>信息系统集成与管理 （97）、计算机视觉与模式识别 （95）、数字图像处理 （94）、数字工程软件架构 （93）、时空数据处理与组织 （93）</li>
</ul>
<p>💻 <strong>编程能力</strong>：</p>
<ul>
<li><strong>编程语言</strong>：熟练使用Python，C/C++，Matlab，JavaScript在内的多种编程语言，并拥有多个实际项目开发经验;</li>
<li><strong>深度学习</strong>：熟悉Pytorch等主流深度学习框架，熟悉Transformer、Diffusers等先进模型库以及Numpy、Pandas、Scikit-learn等常见机器学习库;</li>
<li><strong>高性能计算</strong>：较为了解CUDA和GPU编程; 能够高效地进行多卡训练和分布式计算; 熟悉TVM深度学习编译器，可将模型优化部署至GPU、TPU及边缘设备等硬件平台。</li>
</ul>
<p>🌍 <strong>英语能力</strong>：</p>
<ul>
<li>CET-6 成绩 568 分</li>
<li>分别以第一作者/共同一作的身份主导/参与过全英学术论文的写作投稿</li>
</ul>
<hr>
<h2> 🏆 荣誉奖项  
<ul>
<li>🏅 <strong>NeurIPS 2024 - Ariel Data Challenge (Bronze Medal)</strong></li>
<li>🏅 <strong>全国大学生集成电路创新创业大赛 (国家级二等奖)</strong></li>
<li>🏅 <strong>全国大学生数学竞赛 (国家级二等奖)</strong></li>
<li>🏅 <strong>“高教社杯”全国大学生数学建模竞赛 (省部级一等奖)</strong></li>
<li>🏅 <strong>“华中杯”大学生数学建模挑战赛 (省部级二等奖)</strong></li>
<li>🏅 <strong>COMAP 2024 MCM/ICM (Honorable Mention)</strong></li>
<li>🌟 <strong>国家奖学金 (武汉大学 2022-2023 年度评优)</strong></li>
<li>🌟 <strong>NITORI国际专项奖学金 (武汉大学 2023-2024 年度评优)</strong></li>
<li>🌟 <strong>优秀学生甲等奖学金 (武汉大学 2022-2023 年度评优)</strong></li>
<li>🌟 <strong>优秀学生甲等奖学金 (武汉大学 2023-2024 年度评优)</strong></li>
<li>🌟 <strong>三好学生 (武汉大学 2022-2023 年度评优)</strong></li>
<li>🌟 <strong>三好学生 (武汉大学 2023-2024 年度评优)</strong></li>
</ul>
<hr>
<h2> 🔬 主要研究经历</h2>
<h3> 💡 非配对设定下的无监督红外-可见光行人重识别</h3>
<ul>
<li>
<p><strong>已投稿</strong>于 ICCV 2025 (第一作者)</p>
</li>
<li>
<p>🔍 <strong>研究方向</strong>：计算机视觉、行人重识别、跨模态学习</p>
</li>
<li>
<p>📌 <strong>研究背景</strong>：传统无监督可见光-红外行人重识别(VI-ReID)方法一般是基于“跨模态数据严格配对”的理想化假设，然而现实场景中，可见光与红外图像往往因采集时间、行人轨迹等差异会天然性形成非配对关系，所以这种假设不仅违背实际监控场景的跨模态身份缺失特性，会导致监督信息泄露(依赖人工配对标注)，还会引发两大核心挑战：(1)非配对场景缺乏模态间对应关系，现有基于聚类的伪标签生成方法因跨模态关联缺失产生噪声标签；(2)身份样本的跨模态缺失阻碍特征对齐，进一步加剧模态间分布差异；上述问题严重<strong>制约无监督VI-ReID在现实复杂场景中的实用性与鲁棒性，亟待探索非配对跨模态关联的隐式建模方法</strong>。
</p>
</li>
<li>
<p>📌 <strong>我们的方法</strong>：</p>
<ul>
<li>首次<strong>在真实场景中构建非配对设置下可见光-红外行人重识别基准数据集</strong>，填补了现有研究缺乏跨模态身份缺失场景公开数据的空白，为无监督跨模态学习提供了新的评估标准；</li>
<li>针对非配对场景下跨模态关联缺失问题，提出一种<strong>无监督映射与协同学习(MCL)框架</strong>：通过隐式建模跨模态关联解决现有方法对严格配对数据的依赖，实现了无需人工配对标注的跨模态不变表征学习；</li>
<li>设计一种<strong>跨模态特征映射(CFM)模块</strong>：在特征空间合成跨模态正样本对以补充缺失的配对数据，保证模态间身份一致性；</li>
<li>进一步提出一种<strong>静动态协同(SDC)学习策略</strong>：利用合成的跨模态正样本分别进行聚簇级全局身份匹配和实例级局部特征拉近，通过双重优化机制消除跨模态差异。</li>
</ul>
</li>
<li>
<p>📌 <strong>实验效果</strong>：在多个基准数据集上的实验表明，<strong>我们的方法在非配对设置下显著超越现有无监督方法，同时在传统配对场景中保持具有竞争力的性能</strong>，验证了方法的泛化性与实际应用价值。
</p>
</li>
<li>
<p>📜 <strong>产出成果</strong>：相关论文已完成，并<strong>投稿于ICCV 2025(CCF-A类会议，CV领域三大顶会之一)(我作为第一作者)</strong>。
</p>
</li>
</ul>
<hr>
<h3> 💡 夜间救援任务中的微光红外多模态遥感：异常检测方法回顾  </h3>
<ul>
<li>
<p><strong>已投稿</strong>于 IEEE TGRS (共同第一作者)</p>
</li>
<li>
<p>🔍 <strong>研究方向</strong>：计算机视觉、多模态图像融合、异常检测</p>
</li>
<li>
<p>📌 <strong>研究背景</strong>：夜间应急救援任务常⾯临以下挑战：(1) 传统无人机可见光遥感在夜间低光照条件下难以准确检测目标; (2) 灾后地形复杂、遮挡物多，单⼀模态存在局限性（如红外分辨率低、低光图像易受光照影响）; (3) 救援信息需快速获取，但现有数据驱动方法缺乏适⽤于夜间场景的多模态数据集，传统异常检测算法在复杂环境中误报率高; (4) 因此，目前亟需结合低光与红外多模态遥感技术，通过数据融合和先进的异常检测方法，提高夜间救援效率和精度。</p>
</li>
<li>
<p>📌 <strong>我们的方法</strong>：</p>
<ul>
<li>提出<strong>一种基于频域特征分解的双流融合网络</strong>，结合Transformer(全局特征)与CNN(局部细节)，通过独⽴提取低/高频特征并融合，提升下游检测性能;</li>
<li>提出<strong>首个专为夜间救援设计的多模态遥感数据集 MRSI-NERD</strong>: 包含低光与红外同步图像，涵盖4类场景（正常、跌倒、低温、遮挡），共4087帧全标注数据，真实模拟夜间应急救援环境;</li>
<li>提供了<strong>⼀个夜间应急救援场景下的无监督异常检测方法基准测试</strong>，对8类传统与基于深度学习的异常检测方法进行<strong>全面评估</strong>，使⽤ROC-AUC、FPR、TPR等指标对比性能，为后续研究提供参考基准。</li>
</ul>
</li>
<li>
<p>📌 <strong>实验结果</strong>：在熵(EN)/互信息(MI)/结构相似性(SSIM)等指标上均优于现有算法，显著提高下游异常检测性能。</p>
</li>
<li>
<p>📜 <strong>产出成果</strong>：相关论文已完成，并已于2024.9<strong>投稿于IEEE TGRS(中科院一区、CCF-B类会议，地球科学和遥感领域顶刊)(我作为共同第一作者)</strong>，2024.11反馈为Major Revision，并于2025.1完成Resubmit。</p>
</li>
</ul>
<hr>
<h3> 💡 资源受限条件下的无人平台低功耗多模态遥感夜间应急搜救模型 </h3>
<ul>
<li>
<p><u><strong>已中稿</strong>于 IGARSS 2025</u> (第三作者)</p>
</li>
<li>
<p>🔍 <strong>研究方向</strong>：计算机视觉、目标检测、多模态图像融合、脉冲神经网络</p>
</li>
<li>
<p>📌 <strong>研究背景</strong>：在夜间紧急救援任务中，无人机平台受限于计算资源与能耗，传统的基于人工神经网络的目标检测算法因高计算复杂度与高能耗难以高效部署; 同时，微光与红外图像虽能提供夜间环境下的关键特征，但其多模态数据融合与高效处理需求尚未被充分解决; 为此，亟需结合脉冲神经网络(SNN)与多模态图像融合技术，设计了一种适用于资源受限平台的低功耗目标检测方法，以同时平衡实时性、能效与检测精度。</p>
</li>
<li>
<p>📌 <strong>我们的方法</strong>：</p>
<ul>
<li>提出了<strong>一种专门为夜间紧急救援任务设计的新型低功耗目标检测方法</strong>，基于Spiking-YOLO的SNN低功耗目标检测框架，利用事件驱动的稀疏计算特性来模拟大脑的信息处理，与传统ANN的密集计算相比，实现了更高的能量效率，在保持性能的同时显著降低了能耗; </li>
<li>通过SeAFusion模型<strong>融合低光与红外图像的互补特征</strong>(如纹理细节与热辐射信息)，<strong>结合语义损失与轻量级梯度残差密集块</strong>，生成<strong>兼具高视觉质量与丰富语义信息的融合图像</strong>，以优化后续夜间和复杂环境条件下的目标检测性能。</li>
</li>
</ul>
<li>
<p>📌 <strong>实验结果</strong>：在模拟的应急救援场景中进行了广泛评估，实验结果表明: 我们的方法<strong>相比于基于ANN的Tiny YOLO，将理论功耗降低到1/2000，同时保证性能下降不超过2%</strong>，成功验证了在现实应用的有效性。</p>
</li>
<li>
<p>📜 <strong>产出成果</strong>：</p>
<ul>
    <li>依托武汉大学测绘遥感信息工程国家重点实验室申请为省级大创项目，并在期限内“优秀”结项。</li>
    <li>相关成果已申请<strong>一项国家发明专利(我作为第一发明人)</strong>，目前处于实质审查阶段。</li>
    <li>相关论文已完成，并<strong><u>已中稿于IGARSS 2025</u>(CCF-C类会议)(我作为第三作者)</strong></li>
</ul>
</li>
</li>
</ul>
<hr>
<h3> 💡  NeurIPS - Ariel Data Challenge 2024</h3>
<ul>
    <li>
    <p><strong>铜牌 | 排名：68/1151</strong> (主力队员)</p>
    </li>
    <li>
    <p>🔍 <strong>研究方向</strong>：多模态监督学习</p>
    </li>
    <li>
    <p>📌 <strong>比赛背景</strong>：这场比赛由多个国际知名大学和NeurIPS顶会联合主办，目的是<strong>通过分析天文数据来研究系外行星的大气成分</strong>; 比赛数据包括了从望远镜收集的对每个行星的原始观测数据，参赛者需要从这些观测数据中提取大气光谱，具体为对每个样本预测283种不同波长的光谱数据，以及额外预测与283种波长预测结果一一对应的不确定性，也可理解为额外预测对自己预测结果与真实值之间的误差; 比赛的评价标准将使用高斯对数似然(GLL)函数，对不同波长的预测光谱(wavelength)和相应的不确定性(sigma)与地面对数像素水平光谱进行评估; 简单来说，我们的目标是使对每个行星预测的波长和真实值之间的MSE尽量小，同时对于较大MSE的样本预测更大的不确定性。</p>
    </li>
    <li>
    <p>📌 <strong>我们的方法</strong>：</p>
    <ul>
    <li><strong>均值波长预测</strong>: 对凹陷部分乘以因子 1+s 使得整个信号的凹陷部分理论上被消除，之后使用多项式函数拟合信号曲线，得到合适的 s 值使得刚好能满足将凹陷部分上升到与左右完美衔接上，即为我们最终要计算的波长;</li>
    <li><strong>阶段切割点估计</strong>: 计算区间梯度值并进行梯度卷积操作以避免异常单点值的影响，并根据阶段中间点的周围卷积值和中点卷积值的比例去自适应计算切割区段长度;</li>
    <li><strong>机器学习建模</strong>: 为了解决[波长均值预测无法预测每个波长]的缺点，选则使用机器学习模型实现细致精准预测，先对波长维度使用滑窗的形式提取得到区间波长均值特征，并利用特征数据使用分位数回归器或者简单的神经网络模型去学习精确预测每个波长的值;</li>
    <li><strong>sigma预测</strong>: 采用两种预测方式-[根据对评价函数求导得到sigma标签并基于信号数据预测]和[使用预测的波长作为输入数据预测]。</li>
    </ul>
    </li>
    <li>
    <p>📜 <strong>竞赛结果</strong>：取得了0.6091的final score，<strong>在1151个团队中排名第68位(Top 5.9%)，摘得了一枚铜牌</strong>。</p>
    </li>
</ul>
<hr>
<h2> 🔬 其它研究经历</h2>
<h3> 💡 基于飞腾派的视觉机械臂智能分拣系统</h3>
<ul>
    <li>
    <p>全国集成电路大赛<strong>国家级二等奖</strong> (队长)</p>
    </li>
    <li>
    <p>🔍 <strong>研究方向</strong>：计算机视觉、视觉机械臂系统</p>
    </li>
    <li>
    <p>📌 <strong>比赛背景</strong>：(1)视觉机械臂系统通过远程操控和实时交互，其能够在危险环境中安全作业，显著提高工业生产的效率与质量并带来日常生活的智能化便利; (2)在智能分拣中，将视觉技术与机械臂的抓取动作相结合，极大地提升了机械臂在各领域的智能化水平，使得任务执行更加精准高效; (3)这次比赛中，参赛者被要求去<strong>开发一套基于飞腾派开发板的智能视觉机械臂系统</strong>，该系统需<strong>具备高效的抓取和放置功能并集成了先进的安全制动机制</strong>。</p>
    </li>
    <li>
    <p>📌 <strong>我们的方法</strong>：</p>
    <ul>
    <li><strong>距离感知测量</strong>: 系统首先通过高精度的 STPL32 测距传感器实时监测物体距离。当物体距离降至预设的安全阈值以下，系统将自动向机械臂发出抓取指令，确保操作的及时性和准确性;</li>
    <li><strong>深度视觉分析</strong>: 利用先进的 OAK-D-Lite 深度视觉相机，系统能够精确识别目标物体并实时计算其在3D空间中的位置。经过坐标系转换，系统将目标物体的3D坐标信息传递给机械臂;</li>
    <li><strong>机械臂抓取与移动</strong>: 在接收到抓取指令和目标物体的 3D 空间位置信息后，系统可以计算出机械臂的最佳运动路径和各关节的最优运动方案，机械臂将根据系统计算的结果执行精确的抓取动作，并沿着预设路径平稳移动，完成目标物品的抓取和移动任务;</li>
    <li><strong>OpenAMP核间通信</strong>: 设置机械臂的抓取移动操作在 CPU0(主核) 上进行，双目相机的目标检测和深度计算操作在 CPU2(主核) 上进行，STP-23L 距离传感器的数据采集在 CPU1(从核) 上进行; CPU1(从核) 实时高性能地采集 STP-23L 距离传感器的数据，并利用 OpenAMP 将采集到的距离数据传递给 CPU0(主核)；CPU0(主核) 在获取到距离数据后，进一步地处理分析，将结果通过 OpenAMP 再传递给 CPU1(从核)，CPU1(从核) 根据分析结果提供安全制动功能。</li>
</ul>
    </li>
    <li>
    <p>📜 <strong>竞赛结果</strong>：相关作品获<strong>全国大学生集成电路创新创业大赛</strong>(武汉大学立项竞赛)<strong>国家级二等奖(我作为队长)</strong>。</p>
    </li>
</ul>
<hr>
<h3> 💡  笔韵智枢—大数据驱动的智能一体化字体创作引擎</h3>
<ul>
    <li>
    <p>已推往武汉大学“自强杯”校级决赛 (主力队员)</p>
    </li>
    <li>
    <p>🔍 <strong>研究方向</strong>：生成式人工智能、少样本字体生成</p>
    </li>
    <li>
    <p>📌 <strong>比赛背景</strong>：字库产业是汉字文化在数字世界中的载体，然而目前字体设计行业面临着字体制作难的产业痛点。逐字设计的字体创作方法流程繁琐，耗费成本高，基于开源字体修改的方法则面临着批量生成风格同质化等局限。此外AI字体生成方法也面临着<strong>[参考字结构多样性]</strong>、<strong>[风格杂糅]</strong>，以及<strong>[复杂字形上的泛化能力差]</strong>三大挑战。</p>
    </li>
    <li>
    <p>📌 <strong>我们的方法</strong>：</p>
    <ul>
    <li>借助大数据思想助力模型构建，本作品独创性地提出了<strong>“1个核心模型+2个数据优化模块+3大类型数据集”一站式创作工具的解决方案</strong>;</li>
    <li><strong>核心模型</strong>: 在传统 GAN 网络的基础上，使用多头编码器和匈牙利算法来实现局部特征提取与特征自动匹配;</li>
    <li><strong>数据优化模块</strong>: 针对参考字组件多样性和字体风格杂糅问题，分别设计了基于四角编码映射的参考字推荐优化算法和基于 ResNet-18 网络的源字体匹配优化算法;</li>
    <li><strong>3大类型数据集</strong>: 提出使用大数据优化小样本生成，爬取、收集并标注了三大类型数据，构建带有更多样化字体字形的训练数据集;</li>
    <li>在楷体、圆体、黑体三种风格的字形生成任务上都获得了优良的表现，相比传统AI生成模型，<strong>LPIPS和真人辨识率上的平均表现分别获得33.94%和26.79%的提升</strong>，且极大地<strong>缩短了字体的制作周期和人力成本</strong>。</li>
</ul>
    </li>
    <li>
    <p>📜 <strong>竞赛结果</strong>：相关作品已入围<strong>武汉大学“自强杯”</strong>大学生课外学术科技作品竞赛<strong>校级决赛(入围率20%)</strong>。</p>
    </li>
</ul>
<hr>
<h2> 🌟 社会活动  
<h3> 助理班主任 (武汉大学 遥感信息工程学院 2409 班)   </h3>
<p>🔗 <a target="_blank" rel="noopener" href="https：//rsgis.whu.edu.cn/info/1083/97650.htm">相关链接</a></p>
<ul>
<li>📌 组织面向所负责班级(2409班)同学们的<strong>高数/线代/数据结构与算法</strong>等核心专业课的复习串讲讲座，积极邀请同级的优秀学长学姐(包括自己)分享期末复习经验，所负责班级在2024-2025学年上学期班级均分位列<strong>年级第一</strong></li>
<li>📌 积极面向所负责班级同学们分享关于<strong>科研/数学建模/作品赛</strong>等方面的入门经验和方向指引，收到一致好评</li>
</ul>
<hr>
</h2></h2></article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/about"> 🔍 Detailed Information (CN)</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy；2023 - 2025 by Haoyu Yao (姚皓宇)</div><div class="theme-info">Powered by <a target="_blank" href="https：//hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https：//github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https：//cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https：//cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>
